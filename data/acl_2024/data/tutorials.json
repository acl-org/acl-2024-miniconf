{
    "T0": {
        "anthology_url": null,
        "chairs": [],
        "description": "Computational linguistics (CL) has witnessed tremendous advancements in recent years, with models such as large language models demonstrating exceptional performance in various natural language processing tasks. These advancements highlight their potential to help understand brain language processing, especially through the lens of brain encoding and decoding.",
        "end_time": null,
        "id": "T0",
        "link": null,
        "organizers": [
            "Jingyuan Sun",
            "Shaonan Wang",
            "Zijiao Chen",
            "Jixing Li and Marie-Francine Moens"
        ],
        "paper_ids": [],
        "rocketchat_channel": "tutorial-0",
        "room": null,
        "session": "T0",
        "start_time": null,
        "title": "Computational Linguistics for Brain Encoding and Decoding: Principles, Practices and Beyond",
        "track": "Tutorial",
        "tutorial_pdf": null,
        "type": "Tutorials"
    },
    "T1": {
        "anthology_url": null,
        "chairs": [],
        "description": "In this tutorial, we focus on text-to-text generation, a class of natural language generation (NLG) tasks, that takes a piece of text as input and then generates a revision that is improved according to some specific criteria (e.g., readability or linguistic styles), while largely retaining the original meaning and the length of the text. This includes many useful applications, such as text simplification, paraphrase generation, style transfer, etc. In contrast to text summarization and open-ended text completion (e.g., story), the text-to-text generation tasks we discuss in this tutorial are more constrained in terms of semantic consistency and targeted language styles. This level of control makes these tasks ideal testbeds for studying the ability of models to generate text that is both semantically adequate and stylistically appropriate. Moreover, these tasks are interesting from a technical standpoint, as they require complex combinations of lexical and syntactical transformations, stylistic control, and adherence to factual knowledge, -- all at once. With a special focus on text simplification and revision, this tutorial aims to provide an overview of the state-of-the-art natural language generation research from four major aspects -- Data, Models, Human-AI Collaboration, and Evaluation -- and to discuss and showcase a few significant and recent advances: (1) the use of non-retrogressive approaches; (2) the shift from fine-tuning to prompting with large language models; (3) the development of new learnable metric and fine-grained human evaluation framework; (4) a growing body of studies and datasets on non-English languages; (5) the rise of HCI+NLP+Accessibility interdisciplinary research to create real-world writing assistant systems.",
        "end_time": null,
        "id": "T1",
        "link": null,
        "organizers": [
            "Yao Dou",
            "Philippe Laban",
            "Claire Gardent and Wei Xu"
        ],
        "paper_ids": [],
        "rocketchat_channel": "tutorial-1",
        "room": null,
        "session": "T1",
        "start_time": null,
        "title": "Automatic and Human-AI Interactive Text Generation (with a focus on Text Simplification and Revision) ",
        "track": "Tutorial",
        "tutorial_pdf": null,
        "type": "Tutorials"
    },
    "T2": {
        "anthology_url": null,
        "chairs": [],
        "description": "Language models (LMs) are currently at the forefront of NLP research due to their remarkable versatility across diverse tasks. However, a large gap exists between their observed capabilities and the explanations proposed by established formal machinery. To motivate a better theoretical characterization of LMs' abilities and limitations, this tutorial aims to provide a comprehensive introduction to a specific framework for formal analysis of modern LMs using tools from formal language theory (FLT). We present how tools from FLT can be useful in understanding the inner workings and predicting the capabilities of modern neural LM architectures. We will cover recent results using FLT to make precise and practically relevant statements about LMs based on recurrent neural networks and transformers by relating them to formal devices such as finite-state automata, Turing machines, and analog circuits. Altogether, the results covered in this tutorial will allow us to make precise statements and explanations about the observed as well as predicted behaviors of LMs, as well as provide theoretically motivated suggestions on the aspects of the architectures that could be improved.",
        "end_time": null,
        "id": "T2",
        "link": null,
        "organizers": [
            "Alexandra Butoi",
            "Ryan Cotterell and Anej Svete"
        ],
        "paper_ids": [],
        "rocketchat_channel": "tutorial-2",
        "room": null,
        "session": "T2",
        "start_time": null,
        "title": "Computational Expressivity of Neural Language Models",
        "track": "Tutorial",
        "tutorial_pdf": null,
        "type": "Tutorials"
    },
    "T3": {
        "anthology_url": null,
        "chairs": [],
        "description": "Each year a large number of early career researchers join the NLP/Computational Linguistics community, with most starting by presenting their research in the *ACL conferences and workshops. While writing a paper that has made it to these venues is one important step, what comes with communicating the outcome is equally important and sets the path to impact of a research outcome. In addition, not all PhD candidates get the chance of being trained for their presentation skills. Research methods courses are not all of the same quality and may not cover scientific communications, and certainly not all are tailored to the NLP community. We are proposing an introductory tutorial that covers a range of different communication skills, including writing, oral presentation (posters and demos), and social media presence. This is to fill in the gap for the researchers who may not have access to research methods courses or other mentors who could help them acquire such skills. The interactive nature of such a tutorial would allow attendees to ask questions and clarifications which would not be possible from reading materials alone.",
        "end_time": null,
        "id": "T3",
        "link": null,
        "organizers": [
            "Sarvnaz Karimi",
            "Cecile Paris and Gholamreza Haffari"
        ],
        "paper_ids": [],
        "rocketchat_channel": "tutorial-3",
        "room": null,
        "session": "T3",
        "start_time": null,
        "title": "Presentation Matters: How to Communicate Science in the NLP Venues and in the Wild?",
        "track": "Tutorial",
        "tutorial_pdf": null,
        "type": "Tutorials"
    },
    "T4": {
        "anthology_url": null,
        "chairs": [],
        "description": "This tutorial serves as a comprehensive guide on the vulnerabilities of Large Language Models (LLMs) to adversarial attacks, an interdisciplinary field that blends perspectives from Natural Language Processing (NLP) and Cybersecurity. As LLMs become more complex and integrated into various systems, understanding their security attributes is crucial. However, current research indicates that even safety-aligned models are not impervious to adversarial attacks that can result in incorrect or harmful outputs. The tutorial first lays the foundation by explaining safety-aligned LLMs and concepts in cybersecurity. It then categorizes existing research based on different types of learning architectures and attack methods. We highlight the existing vulnerabilities of unimodal LLMs, multi-modal LLMs, and systems that integrate LLMs, focusing on adversarial attacks designed to exploit weaknesses and mislead AI systems. Finally, the tutorial delves into the potential causes of these vulnerabilities and discusses potential defense mechanisms.",
        "end_time": null,
        "id": "T4",
        "link": null,
        "organizers": [
            "Yu Fu",
            "Erfan Shayegan",
            "Md. Mamun Al Abdullah",
            "Pedram Zaree",
            "Nael Abu-Ghazaleh and Yue Dong"
        ],
        "paper_ids": [],
        "rocketchat_channel": "tutorial-4",
        "room": null,
        "session": "T4",
        "start_time": null,
        "title": "Vulnerabilities of Large Language Models to Adversarial Attacks",
        "track": "Tutorial",
        "tutorial_pdf": null,
        "type": "Tutorials"
    },
    "T5": {
        "anthology_url": null,
        "chairs": [],
        "description": "As AI-generated text increasingly resembles human-written content, the ability to detect machine-generated text becomes crucial in both the computational linguistics and machine learning communities. In this tutorial, we aim to provide an in-depth exploration of text watermarking, a subfield of linguistic steganography with the goal of embedding a hidden message (the watermark) within a text passage. We will introduce the fundamentals of text watermarking, discuss the main challenges in identifying AI-generated text, and delve into the current watermarking methods, assessing their strengths and weaknesses. Moreover, we will explore other possible applications of text watermarking and discuss future directions for this field. Each section will be supplemented with examples and key takeaways.",
        "end_time": null,
        "id": "T5",
        "link": null,
        "organizers": [
            "Xuandong Zhao",
            "Yu-Xiang Wang and Lei Li"
        ],
        "paper_ids": [],
        "rocketchat_channel": "tutorial-5",
        "room": null,
        "session": "T5",
        "start_time": null,
        "title": "Watermarking for Large Language Model",
        "track": "Tutorial",
        "tutorial_pdf": null,
        "type": "Tutorials"
    }
}